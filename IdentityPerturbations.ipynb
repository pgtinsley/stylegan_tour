{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StyleGAN identity perturbations\n",
    "\n",
    "This code is based on the StyleGAN `pretrained_example.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "import config\n",
    "import imageio\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "def randomString(stringLength=10):\n",
    "    \"\"\"Generate a random string of fixed length \"\"\"\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for i in range(stringLength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory for results, if needed\n",
    "os.makedirs('results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    # Initialize TensorFlow.\n",
    "    tflib.init_tf()\n",
    "    # Load pre-trained network.\n",
    "    url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # karras2019stylegan-ffhq-1024x1024.pkl\n",
    "    with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\n",
    "        _G, _D, Gs = pickle.load(f)\n",
    "    return [_G, _D, Gs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "[_G, _D, Gs] = setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a nice random generator state. Replace None with a constant int to\n",
    "# reproduce the same result\n",
    "rnd = np.random.RandomState(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_items: 40\n"
     ]
    }
   ],
   "source": [
    "# Exp 1:\n",
    "# perturb EACH of the coefficients in the latent vector by a different random amount\n",
    "# a standard normal multiplied by a shared gain factor.\n",
    "# generated images are written to a video file\n",
    "# diversity of images depends on the value of \"magnitude\".  0.1 tends to preserve\n",
    "# quasi-identity, gender, expression, pose. Larger values generate variety in all\n",
    "# attributes.\n",
    "# You can run this cell multiple times and get a different output video.\n",
    "\n",
    "# number of images to make\n",
    "num_samples = 40\n",
    "\n",
    "latent = rnd.randn(Gs.input_shape[1])\n",
    "\n",
    "stk = []\n",
    "magnitude = 0.1 # modulate all normal perturbations by this amount\n",
    "\n",
    "for i in range(num_samples):\n",
    "    l2 = latent + magnitude * rnd.randn(Gs.input_shape[1])   # perturb\n",
    "    stk.append(l2)\n",
    "latents = np.stack(stk)\n",
    "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "# Render\n",
    "images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=True, output_transform=fmt)\n",
    "s=images[0].shape\n",
    "\n",
    "# write output images to a video file\n",
    "vfn =  os.path.join('results', 'exp1_'+randomString()+'.avi')\n",
    "videowriter =  cv2.VideoWriter(vfn,cv2.VideoWriter_fourcc(*'mp4v'), 10, (s[1],s[0]))\n",
    "for i in range(num_samples):\n",
    "    videowriter.write(images[i][...,::-1])\n",
    "videowriter.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_items: 55\n"
     ]
    }
   ],
   "source": [
    "# EXP2:\n",
    "# perturb just one element of the latent vector\n",
    "rnd = np.random.RandomState(None)\n",
    "\n",
    "num_samples = 55\n",
    "\n",
    "latent = rnd.randn(Gs.input_shape[1])\n",
    "\n",
    "stk = []\n",
    "magnitude = 10\n",
    "\n",
    "index = 399\n",
    "\n",
    "for i in range(num_samples):\n",
    "    l2 = latent\n",
    "    l2[index] = l2[index] + magnitude * rnd.randn()\n",
    "    stk.append(l2)\n",
    "latents = np.stack(stk)\n",
    "#latents = np.stack([rnd.randn(Gs.input_shape[1]) for _ in range(num_samples)])\n",
    "#latents = rnd.randn(1, Gs.input_shape[1])\n",
    "#latents = np.stack([rnd.randn(Gs.input_shape[1])] * 2)\n",
    "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "\n",
    "# Render\n",
    "images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=True, output_transform=fmt)\n",
    "s=images[0].shape\n",
    "\n",
    "vfn =  os.path.join('results', 'exp2_'+randomString()+'_{0}_{1}.avi'.format(index,magnitude))\n",
    "videowriter =  cv2.VideoWriter(vfn,cv2.VideoWriter_fourcc(*'mp4v'), 10, (s[1],s[0]))\n",
    "for i in range(num_samples):\n",
    "    videowriter.write(images[i][...,::-1])\n",
    "videowriter.release()\n",
    "#    PIL.Image.fromarray(images[i], 'RGB').save(png_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_items: 40\n"
     ]
    }
   ],
   "source": [
    "# Exp 1b:\n",
    "# perturb EACH of the coefficients in the latent vector by a different random amount\n",
    "# a standard normal multiplied by a shared gain factor.\n",
    "\n",
    "# turn off randomize_noise\n",
    "\n",
    "# generated images are written to a video file\n",
    "# diversity of images depends on the value of \"magnitude\".  0.1 tends to preserve\n",
    "# quasi-identity, gender, expression, pose. Larger values generate variety in all\n",
    "# attributes.\n",
    "# You can run this cell multiple times and get a different output video.\n",
    "\n",
    "# number of images to make\n",
    "num_samples = 40\n",
    "\n",
    "latent = rnd.randn(Gs.input_shape[1])\n",
    "\n",
    "stk = []\n",
    "magnitude = 5000 # modulate all normal perturbations by this amount\n",
    "\n",
    "for i in range(num_samples):\n",
    "    l2 = latent + magnitude * rnd.randn(Gs.input_shape[1])   # perturb\n",
    "    stk.append(l2)\n",
    "latents = np.stack(stk)\n",
    "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "# Render\n",
    "images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=False, output_transform=fmt)\n",
    "s=images[0].shape\n",
    "\n",
    "# write output images to a video file\n",
    "vfn =  os.path.join('results', 'exp1b_'+randomString()+'.avi')\n",
    "videowriter =  cv2.VideoWriter(vfn,cv2.VideoWriter_fourcc(*'mp4v'), 10, (s[1],s[0]))\n",
    "for i in range(num_samples):\n",
    "    videowriter.write(images[i][...,::-1])\n",
    "videowriter.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea: discover latent vectors for everyone in a data set. Where do they live?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
