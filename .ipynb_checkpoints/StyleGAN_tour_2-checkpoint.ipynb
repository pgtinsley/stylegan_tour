{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's go on a tour of the StyleGAN latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "import statistics\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Taken from pretrained_example.py\n",
    "import os\n",
    "import pickle\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "import config\n",
    "from encoder.generator_model import Generator\n",
    "\n",
    "# Off-the-shelf recognizer\n",
    "import face_recognition\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot latent vectors of shape 18x512\n",
    "def generate_image(latent_vector):\n",
    "    latent_vector = latent_vector.reshape((1, 18, 512))\n",
    "    generator.set_dlatents(latent_vector)\n",
    "    img_array = generator.generate_images()[0]\n",
    "    img = PIL.Image.fromarray(img_array, 'RGB')\n",
    "    return img.resize((1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    tflib.init_tf()\n",
    "    # Load pre-trained network.\n",
    "    url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # karras2019stylegan-ffhq-1024x1024.pkl\n",
    "    with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\n",
    "        _G, _D, Gs = pickle.load(f)\n",
    "    generator = Generator(Gs, batch_size=1, randomize_noise=False) # -- RUNNING >1 TIMES THROWS ERROR\n",
    "    fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "    return [_G, _D, Gs, generator, fmt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run once.\n",
    "[_G, _D, Gs, generator, fmt] = setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in latent vectors\n",
    "# vec = np.load('latent_representations/kevin_bowyer_01.npy')\n",
    "# vec = np.load('latent_representations/pat_flynn_01.npy')\n",
    "# vec = np.load('latent_representations/walter_scheirer_01.npy')\n",
    "# vec4 = np.load('latent_representations/arnold_schwarzenegger_01.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_perturb(base_vector, axis, pkl_fname, magnitudes=[0.05, 0.1, 0.5, 1, 5]):\n",
    "    \n",
    "    # Get base image.\n",
    "    base_image = generate_image(base_vector)\n",
    "    \n",
    "    # Get base image fr encoding.\n",
    "    base_image_encoding = face_recognition.face_encodings(np.array(base_image))[0]\n",
    "\n",
    "    # Copy base vector.\n",
    "    new_vector = np.copy(base_vector)\n",
    "\n",
    "    return_dict = {}\n",
    "    return_dict['base_vector'] = base_vector\n",
    "    return_dict['axis'] = axis\n",
    "    return_dict['magnitudes'] = magnitudes\n",
    "    \n",
    "    # Loop over magnitudes.\n",
    "    for magnitude in magnitudes:\n",
    "\n",
    "        return_dict[str(magnitude)] = {}\n",
    "\n",
    "        # images = []\n",
    "        sg_distances = []\n",
    "        fr_distances = []\n",
    "        \n",
    "        # Loop over random seeds.\n",
    "        for i in range(100):\n",
    "            \n",
    "            print(i)\n",
    "            \n",
    "            # Assign random state.\n",
    "            rnd = np.random.RandomState(i)\n",
    "            \n",
    "            # Perturb specified axis in new vector.\n",
    "            new_vector[axis] = new_vector[axis] + magnitude * rnd.randn(Gs.input_shape[1])\n",
    "\n",
    "            # Save distance in SG space.\n",
    "            sg_distances.append(np.linalg.norm(base_vector-new_vector))\n",
    "            \n",
    "            # Get new image.\n",
    "            new_image = generate_image(new_vector)\n",
    "            \n",
    "            # # Save image for later.\n",
    "            # images.append(new_image)\n",
    "            \n",
    "            # Get new image fr encoding.\n",
    "            new_image_encodings = face_recognition.face_encodings(np.array(new_image))\n",
    "\n",
    "            # FACE DETECTED/ENCODED\n",
    "            if len(new_image_encodings) > 0:\n",
    "                new_image_encoding = new_image_encodings[0]\n",
    "                fr_distance = face_recognition.face_distance([base_image_encoding], new_image_encoding)[0]\n",
    "\n",
    "            # NO FACE DETECTED\n",
    "            else:\n",
    "                fr_distance = 1.0\n",
    "\n",
    "            # Save distance in FR space.\n",
    "            fr_distances.append(fr_distance)\n",
    "    \n",
    "        # return_dict[str(magnitude)]['images'] = images\n",
    "        return_dict[str(magnitude)]['sg_distances'] = sg_distances\n",
    "        return_dict[str(magnitude)]['fr_distances'] = fr_distances        \n",
    "    \n",
    "    with open(pkl_fname, 'wb') as f:\n",
    "        pickle.dump(return_dict, f)\n",
    "    \n",
    "#     return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.load('latent_representations/kevin_bowyer_01.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "mc_perturb(vec, axis=0, pkl_fname='test.pickle', magnitudes=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirnames = os.listdir('../data/FRGC/FRGC-2.0-dist/nd1/custom_100/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dirnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirnames[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname in dirnames:\n",
    "    vec = np.load('../data/FRGC/FRGC-2.0-dist/nd1/custom_100/' + dirname + '/' + dirname + '_01.npy')\n",
    "    for a in range(18):\n",
    "        pkl_fname2 = '../data/FRGC/FRGC-2.0-dist/nd1/custom_100/' + dirname + '/' + dirname + '_axis' + str(a) + '.pkl'\n",
    "        if not os.path.exists(pkl_fname2):\n",
    "            print('mc_perturb-ing to create '+pkl_fname2)\n",
    "            mc_perturb(vec, axis=a, pkl_fname=pkl_fname2)\n",
    "        else:\n",
    "            print(pkl_fname2 + ' already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
