{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import statistics\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Taken from pretrained_example.py\n",
    "import os\n",
    "import pickle\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "import config\n",
    "from encoder.generator_model import Generator\n",
    "\n",
    "# Off-the-shelf recognizer\n",
    "import face_recognition\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "from scipy.stats import shapiro, normaltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot latent vectors of shape 18x512\n",
    "def generate_image(latent_vector, size=512):\n",
    "    latent_vector = latent_vector.reshape((1, 18, 512))\n",
    "    generator.set_dlatents(latent_vector)\n",
    "    img_array = generator.generate_images()[0]\n",
    "    img = PIL.Image.fromarray(img_array, 'RGB')\n",
    "    return img.resize((size, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    tflib.init_tf()\n",
    "    # Load pre-trained network.\n",
    "    url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # karras2019stylegan-ffhq-1024x1024.pkl\n",
    "    with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\n",
    "        _G, _D, Gs = pickle.load(f)\n",
    "    generator = Generator(Gs, batch_size=1, randomize_noise=False) # -- RUNNING >1 TIMES THROWS ERROR\n",
    "    fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "    return [_G, _D, Gs, generator, fmt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run once.\n",
    "[_G, _D, Gs, generator, fmt] = setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #1 \n",
    "Is the average/centroid of each subject's 4-tuple still recognizable as the same person?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [s.split('/')[-1].split('_')[0] for s in glob.glob('./generated_images/*_centroid.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'04549'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for subject in subjects:\n",
    "#     print(subject)\n",
    "#     lr_hr = glob.glob('./latent_representations/'+subject+'*_hr_*')\n",
    "#     print(lr_hr)\n",
    "#     lr_hr_c = np.load(lr_hr[0]) + np.load(lr_hr[1])\n",
    "#     lat_rep_lr = glob.glob('./latent_representations/'+subject+'*_lr_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_match_rate(subject):\n",
    "#     gi_fnames = glob.glob('./generated_images/'+subject+'*.png')\n",
    "#     # gi_fnames\n",
    "#     c_enc = None\n",
    "#     gi_enc = []\n",
    "#     for fname in gi_fnames:\n",
    "#         img = np.array(Image.open(fname))\n",
    "#         enc = face_recognition.face_encodings(img)\n",
    "#         if len(enc)>0: enc = enc[0]\n",
    "#         else: enc = np.zeros(128,)\n",
    "#         if 'centroid' in fname: c_enc = enc\n",
    "#         else: gi_enc.append(enc)\n",
    "#     distances = face_recognition.compare_faces(gi_enc, c_enc)\n",
    "#     return sum(distances)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_rates = []\n",
    "# for subject in subjects:\n",
    "#     print(subject)\n",
    "#     match_rates.append(get_match_rate(subject))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_match_rates = pd.DataFrame(match_rates, index=subjects, columns=['match_rate'])\n",
    "# df_match_rates['match_rate'].value_counts()\n",
    "# df_match_rates.to_csv('df_match_rates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>match_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4561</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4295</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  match_rate\n",
       "1         4561         0.0\n",
       "28        4295         0.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looks like most (190/192) of the subjects have centroids that are \n",
    "# recognizable when compared to the other images in the 4-tuple.\n",
    "# What are the two exceptions to this:\n",
    "\n",
    "df_match_rates = pd.read_csv('df_match_rates.csv')\n",
    "df_match_rates[df_match_rates['match_rate']!=1.0]\n",
    "\n",
    "# 04561 -- 0 out of 4 images matched against the centroid image's encoding.\n",
    "# 04295 -- 2 out of 4 images matched against the centroid image's encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gi_0 = glob.glob('./generated_images/04561*')\n",
    "# for fname in sorted(gi_0):\n",
    "#     img = np.array(Image.open(fname))\n",
    "#     plt.figure()\n",
    "#     plt.title(fname.split('/')[-1])\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gi_2 = glob.glob('./generated_images/04295*')\n",
    "# for fname in sorted(gi_2):\n",
    "#     img = np.array(Image.open(fname))\n",
    "#     plt.figure()\n",
    "#     plt.title(fname.split('/')[-1])\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this mean? \n",
    "# We can probably sample from anywhere along any interpolating lines between centroid\n",
    "# and one of the four images to get a new face of the same person.\n",
    "# Furthermore, we can probably sample anywhere within the quadrilaterial created by \n",
    "# these interpolating lines.\n",
    "# Let's test this out with PF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at the centroids more in depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_fnames = glob.glob('./generated_images/*_centroid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ci_encs = []\n",
    "# for ci_fname in ci_fnames:\n",
    "#     img = Image.open(ci_fname)\n",
    "#     enc = face_recognition.face_encodings(np.array(img))\n",
    "#     if len(enc)>0: \n",
    "#         enc = enc[0]\n",
    "#     else: \n",
    "#         print('No encoding found for '+ci_fname)\n",
    "#         enc = np.zeros(128,)\n",
    "#     ci_encs.append(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('ci_encs.pkl', 'wb') as f:\n",
    "#     pickle.dump(ci_encs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('ci_encs.pkl', 'rb') as f:\n",
    "#     ci_encs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_lr_fnames = glob.glob('./latent_representations/*_centroid.npy')\n",
    "ci_lr_fnames[21:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_lr_vecs = []\n",
    "for ci_lr_fname in ci_lr_fnames:\n",
    "    ci_lr_vecs.append(np.load(ci_lr_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ci_fnames), len(ci_encs), len(ci_lr_fnames), len(ci_lr_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ci_fnames.pop(1)\n",
    "# ci_encs.pop(1) \n",
    "# ci_lr_fnames.pop(1) \n",
    "# ci_lr_vecs.pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ci_encs = []\n",
    "match_ci_encs = []\n",
    "for enc in ci_encs:\n",
    "    dist_ci_encs.append(face_recognition.face_distance(ci_encs, enc))\n",
    "    match_ci_encs.append(face_recognition.compare_faces(ci_encs, enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ci_lr_vecs = []\n",
    "for vec in ci_lr_vecs:\n",
    "    dist_ci_lr_vecs.append(np.linalg.norm(ci_lr_vecs - vec, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ci_enc_25 = np.array([dist[0:25] for dist in dist_ci_encs[0:25]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_ci_enc_25 = np.array([[int(b) for b in match_ci_encs[i][0:25]] for i in range(25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 3))\n",
    "\n",
    "im1 = ax1.imshow(dist_ci_enc_25, interpolation='nearest', cmap='Blues')\n",
    "\n",
    "ax1.set_title('face_recognition distance\\nbetween subject centroid faces')\n",
    "ax1.set_xlabel('Subject ID')\n",
    "ax1.set_ylabel('Subject ID')\n",
    "\n",
    "fig.colorbar(im1, ax=ax1)\n",
    "\n",
    "im2 = ax2.imshow(match_ci_enc_25, cmap='binary', interpolation='nearest')\n",
    "\n",
    "ax2.set_title('face_recognition binary match\\nbetween subject centroid faces')\n",
    "ax2.set_xlabel('Subject ID')\n",
    "ax2.set_ylabel('Subject ID')\n",
    "\n",
    "fig.colorbar(im2, ax=ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like there are some false positive matches... Let's see how many.\n",
    "fp_record = {}\n",
    "for i in range(len(match_ci_encs)):\n",
    "    match_list = np.array(match_ci_encs[i])\n",
    "    fp_record[i] = np.where(match_list==True)\n",
    "fp_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dist_ci_lr_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dist_ci_encs).shape, np.array(dist_ci_lr_vecs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_fr_distances = df_fr_distances.describe().loc['mean']\n",
    "# _ = plt.hist(mean_fr_distances, bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_normal(data, alpha=0.05, method='shapiro'):\n",
    "#     if method=='shapiro':\n",
    "#         stat, p = shapiro(data)\n",
    "#     else:\n",
    "#         stat, p = normaltest(data)\n",
    "#     print(stat, p)\n",
    "#     if p > alpha:\n",
    "#         print('Sample looks Gaussian (fail to reject H0)')\n",
    "#     else:\n",
    "#         print('Sample not look Gaussian (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_normal(mean_fr_distances, alpha=0.05, method='dagostino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sg_distances = []\n",
    "# for i, centroid_lr_fname in enumerate(centroid_lr_fnames):   \n",
    "#     #false_positives.append(sum(match) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# fig = go.Figure(\n",
    "#     data=[\n",
    "#         go.Surface(z=distances_df.values),\n",
    "#     ]\n",
    "# )\n",
    "# fig.update_layout(\n",
    "#     title='Euclidean distance between centroid encodings', \n",
    "#     autosize=False,\n",
    "#     width=500, \n",
    "#     height=500,\n",
    "#     margin=dict(l=65, r=50, b=65, t=90))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false_positives_df = pd.DataFrame(false_positives, index=centroids, columns=['fp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false_positives_df['fp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = plt.hist(mean_fr_distances, bins='auto') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_centroids(sub1, sub2, steps=60, pkl_fname='interpolate_centroids.pkl'):\n",
    "    \n",
    "#     ensemble_sub1 = subjects[sub1]\n",
    "#     ensemble_sub2 = subjects[sub2]\n",
    "    \n",
    "#     centroid1 = ensemble_sub1['latent_representations_mean']\n",
    "#     centroid2 = ensemble_sub2['latent_representations_mean']\n",
    "    \n",
    "#     centroid_img1 = generate_image(centroid1)\n",
    "#     centroid_img2 = generate_image(centroid2)\n",
    "    \n",
    "    centroid_img1 = Image.open('./generated_images/'+sub1+'_centroid.png')\n",
    "    centroid_img2 = Image.open('./generated_images/'+sub2+'_centroid.png')\n",
    "    \n",
    "    centroid1 = np.load('./latent_representations/'+sub1+'_centroid.png')\n",
    "    centroid2 = np.load('./latent_representations/'+sub2+'_centroid.png')\n",
    "    \n",
    "    vec1_slim = np.reshape(centroid1, [1, centroid1.shape[0] * centroid1.shape[1]])\n",
    "    vec2_slim = np.reshape(centroid2, [1, centroid2.shape[0] * centroid2.shape[1]])\n",
    "    \n",
    "    enc1 = face_recognition.face_encodings(np.array(centroid_img1))[0]\n",
    "    enc2 = face_recognition.face_encodings(np.array(centroid_img2))[0]\n",
    "\n",
    "    known_encodings = [enc1, enc2]\n",
    "    \n",
    "    images = []\n",
    "    fr_distances = []\n",
    "    \n",
    "    z = np.empty((steps, vec1_slim.shape[1]))\n",
    "    for i, alpha in enumerate(np.linspace(start=1.0, stop=0.0, num=steps)):\n",
    "\n",
    "        # Linearly interpolate.\n",
    "        z[i] = (alpha) * vec1_slim + (1.0-alpha) * vec2_slim\n",
    "\n",
    "        # Reshape interpolated vector, and get interpolated image.\n",
    "        curr_vec = np.reshape(z[i], [18, 512]) # back to original shape\n",
    "        curr_img = np.array(generate_image(curr_vec))\n",
    "\n",
    "        curr_enc = face_recognition.face_encodings(curr_img)[0]\n",
    "        fr_distance = face_recognition.face_distance(known_encodings, curr_enc)\n",
    "\n",
    "        images.append(np.array(curr_img))\n",
    "        fr_distances.append(fr_distance)\n",
    "        \n",
    "    return_dict = {\n",
    "        'images': images,\n",
    "        'fr_distances': fr_distances,\n",
    "    }\n",
    "    \n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = interpolate_centroids('04261', '02463')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results['fr_distances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_sub1 = 0\n",
    "# idx_sub2 = 0\n",
    "# for i, pair in enumerate(rd['fr_distances']):\n",
    "#     if pair[0] < 0.4:\n",
    "#         idx_sub1 = i\n",
    "#     if pair[1] > 0.4:\n",
    "#         idx_sub2 = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_sub1, idx_sub2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outwards_from_centroid(subject):\n",
    "\n",
    "    lr_fnames = glob.glob('./latent_representations/'+subject+'*')\n",
    "    lr_fnames\n",
    "\n",
    "    lr_c = None\n",
    "    lr_gi = []\n",
    "    for fname in lr_fnames:\n",
    "        lr = np.load(fname)\n",
    "        if 'centroid' in fname: lr_c = lr\n",
    "        else: lr_gi.append(lr)\n",
    "    # lr_fnames[0], lr_gi[0]\n",
    "\n",
    "    for ep in range(4):\n",
    "        \n",
    "        print('Heading to endpoint: '+str(ep))\n",
    "        center_slim = np.reshape(lr_c, [1, lr_c.shape[0] * lr_c.shape[1]])\n",
    "        endpoint_slim = np.reshape(lr_gi[ep], [1, lr_c.shape[0] * lr_c.shape[1]]) # CHANGE 0 to i LATER\n",
    "        \n",
    "        center_img = Image.open('./generated_images/04261_centroid.png')\n",
    "        endpoint_img = Image.open(\n",
    "            './generated_images/'+lr_fnames[ep].split('/')[-1][:-3]+'png'\n",
    "        )\n",
    "        \n",
    "        center_enc = face_recognition.face_encodings(np.array(center_img))\n",
    "        if len(center_enc)>0: center_enc = center_enc[0]\n",
    "        else: center_enc = np.zeros(128,)\n",
    "        \n",
    "        endpoint_enc = face_recognition.face_encodings(np.array(endpoint_img))\n",
    "        if len(endpoint_enc)>0: endpoint_enc = endpoint_enc[0]\n",
    "        else: endpoint_enc = np.zeros(128,)  \n",
    "        \n",
    "        known_encodings = [center_enc, endpoint_enc]\n",
    "    \n",
    "        images = []\n",
    "        fr_distances = []\n",
    "\n",
    "        steps = 30\n",
    "        z = np.empty((steps, center_slim.shape[1]))\n",
    "        for i, alpha in enumerate(np.linspace(start=1.0, stop=0.0, num=steps)):\n",
    "\n",
    "            # Linearly interpolate.\n",
    "            z[i] = (alpha) * center_slim + (1.0-alpha) * endpoint_slim\n",
    "\n",
    "            # Reshape interpolated vector, and get interpolated image.\n",
    "            curr_vec = np.reshape(z[i], [18, 512]) # back to original shape\n",
    "            curr_img = np.array(generate_image(curr_vec))\n",
    "\n",
    "            curr_enc = face_recognition.face_encodings(curr_img)\n",
    "            if len(curr_enc)>0: curr_enc = curr_enc[0]\n",
    "            else: curr_enc = np.zeros(128,)          \n",
    "            fr_distance = face_recognition.face_distance(known_encodings, curr_enc)\n",
    "\n",
    "            images.append(np.array(curr_img))\n",
    "            fr_distances.append(fr_distance)\n",
    "            \n",
    "        s = images[0].shape\n",
    "        steps = 30\n",
    "        videowriter =  cv2.VideoWriter('./pf_endpoint'+str(ep)+'.avi', cv2.VideoWriter_fourcc(*'mp4v'), steps/10, (s[1], s[0]))\n",
    "        for i in range(len(images)):\n",
    "            videowriter.write(images[i][...,::-1])\n",
    "        videowriter.release()   \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
